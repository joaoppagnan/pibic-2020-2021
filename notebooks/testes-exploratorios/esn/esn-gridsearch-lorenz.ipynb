{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba3d85c",
   "metadata": {},
   "source": [
    "# Implementando uma ESN com Grid Search para escolher melhor os parâmetros no Sistema de Lorenz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cc5771",
   "metadata": {},
   "source": [
    "## 1. Importando as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c945b",
   "metadata": {},
   "source": [
    "### 1.1 Bibliotecas gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "8fe7bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "plt.rcParams['savefig.dpi'] = 200\n",
    "plt.rcParams[\"figure.dpi\"] = 125\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819c606b",
   "metadata": {},
   "source": [
    "### 1.2 Bibliotecas dos sistemas caóticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "471b3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pibic2020.tools import timeseries\n",
    "from pibic2020.data import lorenz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6822aa3b",
   "metadata": {},
   "source": [
    "### 1.3 *Gridsearch* na ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "5335e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pibic2020.models import esn_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "3c42ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pibic2020.models.esn_model.py\n",
    "\n",
    "from typing import Type\n",
    "import numpy as np\n",
    "from numpy.linalg import pinv, eigvals, inv\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class ModeloESN(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, n_neurons=30, spectral_radius=[1], win_max=1, leaky_values=[0.9], percent_transitory_samples=0.0):\n",
    "        \"\"\"\n",
    "        Descrição:\n",
    "        ----------\n",
    "        Construtor da classe 'ModeloESN'\n",
    "\n",
    "        Parâmetros:\n",
    "        -----------\n",
    "        num_neuronios: int\n",
    "            Número de neurônios por reservatório\n",
    "        leaky_values: list\n",
    "            Lista com os coeficientes de vazamento\n",
    "        spectral_radius: int\n",
    "            Valor com o raio espectral\n",
    "        scale: int ou float\n",
    "            Valor absoluto máximo aceito para os pesos de entrada\n",
    "        percent_transitory_samples = float\n",
    "            Fração de valores de entrada que estarão no conjunto do transitório\n",
    "\n",
    "        Retorna:\n",
    "        --------\n",
    "        Nada\n",
    "        \"\"\"\n",
    "\n",
    "        if not ((type(n_neurons) is int) or (n_neurons is None)):\n",
    "            raise TypeError(\"O número de neurônios deve ser um inteiro!\")\n",
    "\n",
    "        if not (type(leaky_values) is list):\n",
    "            raise TypeError(\"A lista com os coeficientes de vazamento deve ser uma lista!\")   \n",
    "\n",
    "        if not ((type(spectral_radius) is int) or (type(spectral_radius) is float) or (type(spectral_radius) is list)):\n",
    "            raise TypeError(\"O raio espectral deve ser um inteiro ou um float!\")                 \n",
    "\n",
    "        if not (type(percent_transitory_samples) is float):\n",
    "            raise TypeError(\"A fração de amostras do transitório deve ser um float!\")\n",
    "            \n",
    "        self.n_neurons = n_neurons\n",
    "        self.leaky_values = leaky_values\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.win_max = win_max\n",
    "        self.percent_transitory_samples = percent_transitory_samples\n",
    "\n",
    "        # inicializa alguns parâmetros padrões da rede\n",
    "        self._n_reserv = 1\n",
    "        self._W_in = []\n",
    "        self._W_reserv = []\n",
    "        self._state_reserv = []\n",
    "        self._reserv_vector = []\n",
    "        self._W_out = []\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_treino, y_treino):\n",
    "        \"\"\"\n",
    "        Descrição:\n",
    "        ----------\n",
    "        Constrói as matrizes aleatórias do reservatório, computa a matriz com os estados da rede\n",
    "        e obtém a matriz de pesos de saída através da solução de quadrados mínimos (pseudo-inversa)\n",
    "\n",
    "        Parâmetros:\n",
    "        -----------\n",
    "        X_treino: np.ndarray\n",
    "            Conjunto de entradas para o treinamento\n",
    "        y_treino: np.ndarray\n",
    "            Conjunto de saidas para o treinamento\n",
    "\n",
    "        Retorna:\n",
    "        --------\n",
    "        Nada\n",
    "        \"\"\"\n",
    "\n",
    "        if not (type(X_treino) is np.ndarray):\n",
    "            raise TypeError(\"Os dados de entrada de treino devem ser um array do numpy!\")\n",
    "\n",
    "        if not (type(y_treino) is np.ndarray):\n",
    "            raise TypeError(\"Os dados de saída de treino devem ser um array do numpy!\")    \n",
    "\n",
    "        # calcula o numero de amostras de transitorio\n",
    "        n_transitory_samples = int(self.percent_transitory_samples*len(y_treino))\n",
    "\n",
    "        # ajusta o formato das entradas\n",
    "        X_treino = X_treino.T\n",
    "        y_treino = y_treino.T\n",
    "\n",
    "        # extrai o número de atributos de entrada e o número de padrões do conjunto de treinamento (com transitório)\n",
    "        K, n_samples = X_treino.shape\n",
    "        \n",
    "        # número de padrões efetivos do conjunto de treinamento\n",
    "        n_effective_samples = n_samples - n_transitory_samples\n",
    "        \n",
    "        # inicializa a matriz que contém a concatenação dos estados dos reservatórios\n",
    "        self._reserv_vector = np.zeros((self.n_neurons*self._n_reserv, n_effective_samples))\n",
    "        \n",
    "        for l in range(0, self._n_reserv):\n",
    "            \n",
    "            # inicializa a matriz com os estados do l-ésimo reservatório\n",
    "            layer_state = np.zeros((self.n_neurons, n_samples + 1))\n",
    "            \n",
    "            # número de entradas do reservatório l\n",
    "            if (l == 0):\n",
    "                n_layer_inputs = K\n",
    "                layer_input = X_treino\n",
    "            else:\n",
    "                n_layer_inputs = self.n_neurons\n",
    "                \n",
    "                # a entrada da l-ésima camada é o vetor de saída da (l-1)-ésima camada (excluindo o estado inicial)\n",
    "                layer_input = np.delete(self._state_reserv[l-1], 0, 1)\n",
    "            \n",
    "            # matriz de pesos de entrada (W_layer_in) do reservatório l: n_neurons x n_layer_inputs\n",
    "            W_layer_in = 2*self.win_max*np.random.rand(self.n_neurons, n_layer_inputs) - self.win_max\n",
    "            self._W_in.append(W_layer_in)\n",
    "            \n",
    "            # matriz de pesos recorrentes do reservatório l\n",
    "            W_layer = 2*np.random.rand(self.n_neurons, self.n_neurons) - 1\n",
    "            W_spectral = (1 - self.leaky_values[l])*np.eye(self.n_neurons) + self.leaky_values[l]*W_layer\n",
    "            max_eigenvalue = max(abs(eigvals(W_spectral)))\n",
    "            Ws = (self.spectral_radius[l]/max_eigenvalue)*W_spectral\n",
    "            W_layer = (1/self.leaky_values[l])*(Ws - (1 - self.leaky_values[l])*np.eye(self.n_neurons))\n",
    "            self._W_reserv.append(W_layer)\n",
    "            \n",
    "            # computa o estado do reservatório l para todos os instantes do conjunto de treinamento\n",
    "            for i in range(0, n_samples):\n",
    "                \n",
    "                layer_state[:, i + 1] = (1-self.leaky_values[l])*layer_state[:, i] + self.leaky_values[l]*np.tanh(np.matmul(self._W_in[l], layer_input[:, i]) + np.matmul(self._W_reserv[l], layer_state[:, i]))\n",
    "                    \n",
    "            self._state_reserv.append(layer_state)\n",
    "            \n",
    "        for l in range(0, self._n_reserv):           \n",
    "            # elimina a primeira coluna (estado inicial com zeros) e os primeiros n_transitory_samples estados (transitório)\n",
    "            # concatena a matriz de estados do reservatório l ao repositório completo\n",
    "            self._reserv_vector[l*self.n_neurons:(l + 1)*self.n_neurons, :] = self._state_reserv[l][:, n_transitory_samples + 1:]\n",
    "        \n",
    "        # Agora, basta computar a pseudo-inversa da matriz reserv_vector para determinar os pesos da camada de saída         \n",
    "        self._W_out = np.matmul(pinv(self._reserv_vector.T), y_treino[0, n_transitory_samples:].T)\n",
    "        self._W_out = self._W_out.T\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_teste):\n",
    "        \"\"\"\n",
    "        Descrição:\n",
    "        ----------\n",
    "        Obtém as saídas da ESN para o conjunto de teste\n",
    "\n",
    "        Parâmetros:\n",
    "        -----------\n",
    "        X_teste: np.ndarray\n",
    "            Conjunto de entradas para os dados de teste\n",
    "        n_transitory_samples: int\n",
    "            número de amostras para o transitório (inicializar o vetor de estado)\n",
    "\n",
    "        Retorna:\n",
    "        --------\n",
    "        As saídas previstas\n",
    "        \"\"\"\n",
    "\n",
    "        if not (type(X_teste) is np.ndarray):\n",
    "            raise TypeError(\"Os dados de entrada de teste devem ser um array do numpy!\")\n",
    "        \n",
    "        # calcula o numero de amostras de transitorio\n",
    "        n_transitory_samples = int(self.percent_transitory_samples*len(X_teste))\n",
    "\n",
    "        # ajusta o formato da entrada\n",
    "        X_teste = X_teste.T\n",
    "\n",
    "        # extrai o número de padrões do conjunto de teste\n",
    "        n_test_samples = X_teste.shape[1]\n",
    "        \n",
    "        # inicializa a matriz com os estados concatenados (partimos do último estado observado no treinamento)\n",
    "        reserv_vector_test = np.zeros((self.n_neurons*self._n_reserv, n_test_samples - n_transitory_samples))\n",
    "        \n",
    "        # inicializa a lista que vai guardar as matrizes com os estados de cada reservatório (para todos os instantes de teste)\n",
    "        state_reserv_test = []\n",
    "        \n",
    "        for l in range(0, self._n_reserv):\n",
    "            \n",
    "            # inicializa a matriz com os estados do l-ésimo reservatório (o estado inicial equivale ao último do treinamento)\n",
    "            layer_state = np.zeros((self.n_neurons, n_test_samples + 1))\n",
    "            layer_state[:, 0] = self._state_reserv[l][:, -1]\n",
    "            \n",
    "            if (l == 0):\n",
    "                layer_input = X_teste\n",
    "            else:\n",
    "                # a entrada da l-ésima camada é o vetor de saída da (l-1)-ésima camada (excluindo o estado inicial)\n",
    "                layer_input = state_reserv_test[l - 1]\n",
    "            \n",
    "            # computa o estado do reservatório l para todos os instantes do conjunto de teste\n",
    "            for i in range(0, n_test_samples):\n",
    "                layer_state[:, i + 1] = (1 - self.leaky_values[l])*layer_state[:, i] + self.leaky_values[l]*np.tanh(np.matmul(self._W_in[l], layer_input[:, i]) + np.matmul(self._W_reserv[l], layer_state[:, i]))\n",
    "                    \n",
    "            # elimina a primeira coluna (estado inicial com zeros)\n",
    "            state_reserv_test.append(np.delete(layer_state, 0, 1))\n",
    "        \n",
    "        # elimina os primeiros n_transitory_samples estados de todas as camadas\n",
    "        for l in range(0, self._n_reserv):\n",
    "            reserv_vector_test[l*self.n_neurons:(l + 1)*self.n_neurons, :] = np.delete(state_reserv_test[l], np.arange(n_transitory_samples), 1)\n",
    "            \n",
    "        # gera as saídas para o conjunto de teste\n",
    "        y_predicao = np.matmul(self._W_out, reserv_vector_test).T\n",
    "\n",
    "        return y_predicao\n",
    "\n",
    "    def _resetar_rede(self):\n",
    "        \"\"\"\n",
    "        Descrição:\n",
    "        ----------\n",
    "        Método interno para resetar os parâmetros da rede estimados com o treinar().\n",
    "        Utilizado no método avaliar()\n",
    "\n",
    "        Parâmetros:\n",
    "        -----------\n",
    "        Nenhum\n",
    "\n",
    "        Retorna:\n",
    "        --------\n",
    "        Nada\n",
    "        \"\"\"\n",
    "\n",
    "        self._W_in = []\n",
    "        self._W_reserv = []\n",
    "        self._state_reserv = []\n",
    "        self._reserv_vector = []\n",
    "        self._W_out = []\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65364801",
   "metadata": {},
   "source": [
    "## 2. Gerando a série temporal do sistema de Lorenz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdedd6d",
   "metadata": {},
   "source": [
    "Os valores para os parâmetros das equações serão os \"básicos\" apresentados no *paper* original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "94e4b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_inicial = 0\n",
    "t_final = 50\n",
    "dt = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "667d81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estado_inicial = np.array([0.1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "0a1164e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sis_lorenz = lorenz.SistemaLorenz(estado_inicial, dt=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "100e277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "solucoes, instantes_temporais = sis_lorenz.calcular(t_inicial = t_inicial, t_final = t_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "8e68ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = solucoes[:, 0]\n",
    "y = solucoes[:, 1]\n",
    "z = solucoes[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a7ec5",
   "metadata": {},
   "source": [
    "### 2.1 Dividindo em um conjunto de treinamento e de teste, para K = 4 e L = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "d2feb026",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4\n",
    "L = 3\n",
    "tam_teste = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "e41f9f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_temporal = timeseries.SerieTemporal(x, K=K, L=L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "dd4656a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = serie_temporal.dividir_treino_teste(tam_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7ff44c",
   "metadata": {},
   "source": [
    "## 3. Definindo o modelo para a ESN e executando os Gridsearches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "f662987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = TimeSeriesSplit(n_splits=4, test_size=int(0.1*len(y_treino)), gap=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c775ea47",
   "metadata": {},
   "source": [
    "### 3.1 Criando o objeto da ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d8fdd8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "esn = ModeloESN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928ae1cb",
   "metadata": {},
   "source": [
    "Utilizaremos os seguintes parâmetros no *Grid Search*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "d491cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_radius = [[0.1], [0.2], [0.3], [0.4], [0.5],\n",
    "                   [0.6], [0.7], [0.8], [0.9], [0.95],\n",
    "                   [0.96], [0.97], [0.98], [0.99], [1]]\n",
    "\n",
    "n_neurons = [30, 50, 70, 90, 100, 120, 140, 160, 180, 200, 240, 280, 320, 360, 400, 440, 480, 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3519c9",
   "metadata": {},
   "source": [
    "Para facilitar, dividiremos esse processo em etapas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54fe6a",
   "metadata": {},
   "source": [
    "### 3.2 Definindo e executando o primeiro *Grid Search*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e1de45",
   "metadata": {},
   "source": [
    "Primeiro, avaliaremos o conjunto de *n_neurons* com o *spectral_radius*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "6b511620",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_1 = dict(spectral_radius=spectral_radius,\n",
    "                    n_neurons=n_neurons_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "cc0feae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=esn, param_grid=param_grid_1, n_jobs=1, cv=holdout, scoring='neg_mean_squared_error', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "314a6945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 270 candidates, totalling 1080 fits\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "3a4ac7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.000148 using {'n_neurons': 120, 'spectral_radius': [0.2]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c5719",
   "metadata": {},
   "source": [
    "## Teste com o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "010921fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "esn = ModeloESN(n_neurons=120, spectral_radius=[0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "54cfc26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeloESN(n_neurons=120, spectral_radius=[0.2])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esn.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "8b6e48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = esn.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "f245c9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec4a35d84c146cd810b1d967a716a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(instantes_temporais[len(instantes_temporais)-int(len(instantes_temporais)*tam_teste):,], y_teste, color='DarkBlue', label='Valor real', linewidth=0.9)\n",
    "ax.plot(instantes_temporais[len(instantes_temporais)-int(len(instantes_temporais)*tam_teste):,], y_pred, color='DimGrey', label='ESN', linewidth=0.9)\n",
    "\n",
    "ax.set_title(\"Comparação da predição da ESN com o valor real do sistema de Lorenz\\n utilizando a rede recorrente ótima no conjunto de teste\")\n",
    "ax.set_ylabel('$x(t)$')\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_xlim(42.5, 50)\n",
    "    \n",
    "ax.grid(True)\n",
    "sns.despine()\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cdc57b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
