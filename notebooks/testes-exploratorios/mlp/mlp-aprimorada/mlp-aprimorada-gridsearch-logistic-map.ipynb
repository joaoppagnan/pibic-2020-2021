{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementando uma MLP básica com Grid Search para escolher melhor os parâmetros no Mapa Logístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importando as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Bibliotecas gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # a biblioteca 'seaborn' contém vários estilos para os gráficos do 'matpĺotlib'\n",
    "\n",
    "# agora, melhoramos a qualidade de saida e de visualizacao da imagem \n",
    "# alem de mudar a fonte padrao para uma do latex\n",
    "sns.set_style(\"ticks\")\n",
    "plt.rcParams['savefig.dpi'] = 200\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "})\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Bibliotecas para MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Bibliotecas dos sistemas caóticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0, '../../../../scripts')\n",
    "\n",
    "import timeseries as times\n",
    "import logisticmap as logmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gerando a série temporal do mapa logístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores para os parâmetros das equações serão os \"básicos\" apresentados no *paper* original. Utilizaremos  $r = 3.86$, o que faz com que o sistema esteja em caos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inicial = 0.5\n",
    "n_inicial = 0\n",
    "n_iteracoes = 5000\n",
    "r=3.86\n",
    "estados = np.array([x_inicial, n_inicial])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa = logmap.MapaLogistico(estado_inicial=estados, r=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0, n_iteracoes):\n",
    "    mapa.iterar()\n",
    "    estados = np.vstack((estados, mapa.ler_estado()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = estados[:, 0]\n",
    "n = estados[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1379bb9a027d4f23aeb072c40a225aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(n, x, color='Crimson')\n",
    "\n",
    "ax.set_title(\"$100$ iterações iniciais da série temporal do Mapa Logístico\\n para $r =$ \" + str(r) + \" com $x[0] =$ \" + str(x[0]))\n",
    "ax.set_ylabel('$x[n]$')\n",
    "ax.set_xlabel('$n$')\n",
    "ax.set_xlim(0,100)\n",
    "    \n",
    "ax.grid(True)\n",
    "sns.despine()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dividindo em um conjunto de treinamento e de teste, para K = 4 e L = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4\n",
    "L = 3\n",
    "tam_teste = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_temporal = times.SerieTemporal(x, K=K, L=L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_temporal.criar_matrizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = serie_temporal.dividir_treino_teste(tam_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Definindo o modelo para a MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Definindo função para criar a MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_modelo(batch_normalization='OFF', learning_rate=0.001, activation='selu', init_mode='lecun_normal', n_neurons=30):\n",
    "\n",
    "    optimizer_gs = optimizer\n",
    "    optimizer_gs.learning_rate.assign(learning_rate)\n",
    "    \n",
    "    model = keras.Sequential(name=\"MLP-1-camada-intermediaria\")\n",
    "    model.add(keras.layers.Dense(K, input_dim=K, name=\"camada_de_entrada\", activation = 'linear'))\n",
    "    if (batch_normalization == 'ON'):\n",
    "        model.add(keras.layers.BatchNormalization(name=\"camada_de_batch_normalization\"))\n",
    "    model.add(keras.layers.Dense(n_neurons, input_dim=K, activation=activation, kernel_initializer=init_mode, name=\"camada_intermediaria\"))\n",
    "    model.add(keras.layers.Dense(1, activation='linear', name=\"camada_de_saida\"))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = optimizer_gs,\n",
    "        loss = loss)\n",
    "    \n",
    "    model.build()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos os seguintes parâmetros no *Grid Search*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(batch_size=[2, 4, 8, 16, 32], \n",
    "                  batch_normalization=['ON', 'OFF'], \n",
    "                  activation=['selu', 'relu', 'elu', 'sigmoid', 'tanh'], \n",
    "                  init_mode = ['lecun_uniform', 'lecun_normal', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],\n",
    "                  n_neurons = [5, 10, 15, 20, 30, 50, 75, 100],\n",
    "                  learning_rate = [0.001, 0.003, 0.005, 0.008, 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar, dividiremos esse processo em etapas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Definindo parâmetros que não serão definidos pelo *Grid Search*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = \"mean_squared_error\"\n",
    "optimizer = keras.optimizers.Nadam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Definindo e executando o primeiro *Grid Search*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, avaliaremos o impacto do *batch size* e da camada de *batch normalization*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_1 = dict(batch_size=[2, 4, 8, 16, 32], \n",
    "                  batch_normalization=['ON', 'OFF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv_1 = KerasRegressor(build_fn=criar_modelo, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model_cv_1, param_grid=param_grid_1, n_jobs=1, cv=4, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.003760 using {'batch_normalization': 'OFF', 'batch_size': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.178369 (0.082721) with: {'batch_normalization': 'ON', 'batch_size': 2}\n",
      "-0.041401 (0.001848) with: {'batch_normalization': 'ON', 'batch_size': 4}\n",
      "-0.033766 (0.002479) with: {'batch_normalization': 'ON', 'batch_size': 8}\n",
      "-0.021201 (0.001527) with: {'batch_normalization': 'ON', 'batch_size': 16}\n",
      "-0.015921 (0.001640) with: {'batch_normalization': 'ON', 'batch_size': 32}\n",
      "-0.003760 (0.000865) with: {'batch_normalization': 'OFF', 'batch_size': 2}\n",
      "-0.023976 (0.005225) with: {'batch_normalization': 'OFF', 'batch_size': 4}\n",
      "-0.016608 (0.007290) with: {'batch_normalization': 'OFF', 'batch_size': 8}\n",
      "-0.024697 (0.003882) with: {'batch_normalization': 'OFF', 'batch_size': 16}\n",
      "-0.027041 (0.002253) with: {'batch_normalization': 'OFF', 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Definindo e executando o segundo *Grid Search*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, avaliaremos o impacto do *learning rate* do otimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv_2 = KerasRegressor(build_fn=criar_modelo, epochs=100, verbose=0, batch_size=2, batch_normalization='OFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_2 = dict(learning_rate=[0.001, 0.003, 0.005, 0.008, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model_cv_2, param_grid=param_grid_2, n_jobs=1, cv=4, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.007609 using {'learning_rate': 0.003}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.013338 (0.011113) with: {'learning_rate': 0.001}\n",
      "-0.007609 (0.008557) with: {'learning_rate': 0.003}\n",
      "-0.017000 (0.010723) with: {'learning_rate': 0.005}\n",
      "-0.031569 (0.010900) with: {'learning_rate': 0.008}\n",
      "-0.043478 (0.004508) with: {'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Definindo e executando o terceiro *Grid Search*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, avaliaremos o impacto da função de ativação da camada intermediária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv_3 = KerasRegressor(build_fn=criar_modelo, epochs=100, verbose=0, batch_size=2, batch_normalization='OFF', learning_rate=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_3 = dict(activation=['selu', 'relu', 'elu', 'sigmoid', 'tanh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model_cv_3, param_grid=param_grid_3, n_jobs=1, cv=4, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.000939 using {'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.006868 (0.002487) with: {'activation': 'selu'}\n",
      "-0.001459 (0.000349) with: {'activation': 'relu'}\n",
      "-0.013469 (0.011514) with: {'activation': 'elu'}\n",
      "-0.000989 (0.001287) with: {'activation': 'sigmoid'}\n",
      "-0.000939 (0.000318) with: {'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Definindo e executando o quarto *Grid Search*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, avaliaremos o impacto do inicializador da camada intermediária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv_4 = KerasRegressor(build_fn=criar_modelo, epochs=100, verbose=0, batch_size=2, batch_normalization='OFF', learning_rate=0.003, activation='tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_4 = dict(init_mode = ['glorot_uniform', 'glorot_normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model_cv_4, param_grid=param_grid_4, n_jobs=1, cv=4, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.003020 using {'init_mode': 'glorot_uniform'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.003020 (0.002229) with: {'init_mode': 'glorot_uniform'}\n",
      "-0.005604 (0.007977) with: {'init_mode': 'glorot_normal'}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Definindo e executando o quinto *Grid Search*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, avaliaremos o número de neurônios na camada intermediária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv_5 = KerasRegressor(build_fn=criar_modelo, epochs=100, verbose=0, batch_size=2, batch_normalization='OFF', learning_rate=0.003, activation='tanh', init_mode='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_5 = dict(n_neurons = [5, 10, 15, 20, 30, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model_cv_5, param_grid=param_grid_5, n_jobs=1, cv=4, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.001795 using {'n_neurons': 10}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.007413 (0.006256) with: {'n_neurons': 5}\n",
      "-0.001795 (0.001840) with: {'n_neurons': 10}\n",
      "-0.003611 (0.002886) with: {'n_neurons': 15}\n",
      "-0.002872 (0.002484) with: {'n_neurons': 20}\n",
      "-0.005684 (0.006433) with: {'n_neurons': 30}\n",
      "-0.013174 (0.010937) with: {'n_neurons': 50}\n",
      "-0.018582 (0.017341) with: {'n_neurons': 75}\n",
      "-0.010835 (0.007711) with: {'n_neurons': 100}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino com o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = criar_modelo(batch_normalization='OFF', learning_rate=0.003, activation='tanh', init_mode='glorot_uniform', n_neurons=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP-1-camada-intermediaria\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "camada_de_entrada (Dense)    (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "camada_intermediaria (Dense) (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "camada_de_saida (Dense)      (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_val, y_treino, y_val = train_test_split(X_treino, y_treino, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1910/1910 [==============================] - 3s 1ms/step - loss: 0.0588 - val_loss: 0.0565\n",
      "Epoch 2/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0509 - val_loss: 0.0546\n",
      "Epoch 3/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0512 - val_loss: 0.0524\n",
      "Epoch 4/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0493 - val_loss: 0.0536\n",
      "Epoch 5/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0447 - val_loss: 0.0477\n",
      "Epoch 6/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0414 - val_loss: 0.0460\n",
      "Epoch 7/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0392 - val_loss: 0.0448\n",
      "Epoch 8/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0369 - val_loss: 0.0420\n",
      "Epoch 9/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0344 - val_loss: 0.0378\n",
      "Epoch 10/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0330 - val_loss: 0.0371\n",
      "Epoch 11/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0321 - val_loss: 0.0369\n",
      "Epoch 12/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0322 - val_loss: 0.0339\n",
      "Epoch 13/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0302 - val_loss: 0.0343\n",
      "Epoch 14/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0310 - val_loss: 0.0327\n",
      "Epoch 15/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0295 - val_loss: 0.0344\n",
      "Epoch 16/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0287 - val_loss: 0.0301\n",
      "Epoch 17/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0272 - val_loss: 0.0285\n",
      "Epoch 18/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0264 - val_loss: 0.0269\n",
      "Epoch 19/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0248 - val_loss: 0.0262\n",
      "Epoch 20/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0236 - val_loss: 0.0255\n",
      "Epoch 21/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0238 - val_loss: 0.0247\n",
      "Epoch 22/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0241 - val_loss: 0.0251\n",
      "Epoch 23/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0237 - val_loss: 0.0244\n",
      "Epoch 24/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0219 - val_loss: 0.0229\n",
      "Epoch 25/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0243 - val_loss: 0.0250\n",
      "Epoch 26/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0229 - val_loss: 0.0228\n",
      "Epoch 27/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0233 - val_loss: 0.0225\n",
      "Epoch 28/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0221 - val_loss: 0.0224\n",
      "Epoch 29/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0226 - val_loss: 0.0225\n",
      "Epoch 30/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0208 - val_loss: 0.0228\n",
      "Epoch 31/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0206 - val_loss: 0.0235\n",
      "Epoch 32/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0196 - val_loss: 0.0227\n",
      "Epoch 33/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0179 - val_loss: 0.0180\n",
      "Epoch 34/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0170 - val_loss: 0.0160\n",
      "Epoch 35/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0125 - val_loss: 0.0090\n",
      "Epoch 36/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0072 - val_loss: 0.0042\n",
      "Epoch 37/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 38/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 39/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 40/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 41/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 42/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 43/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 44/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 45/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 46/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 47/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 48/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 49/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 50/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0014 - val_loss: 9.7640e-04\n",
      "Epoch 52/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 53/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 54/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 55/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 56/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 57/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 58/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 59/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 60/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 61/100\n",
      "1910/1910 [==============================] - 2s 1ms/step - loss: 0.0012 - val_loss: 9.8897e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_treino, y_treino, epochs=100,\n",
    "                            callbacks=early_stopping, validation_data=(X_val, y_val),\n",
    "                            batch_size=batch_size)\n",
    "treinamento = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste com o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd3ccec4b424cd0a653c0f9c4f74db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(n[len(n)-int(len(n)*tam_teste):,], y_teste, color='Crimson', label='Valor real')\n",
    "ax.plot(n[len(n)-int(len(n)*tam_teste):,], y_pred, color='Silver', label='MLP')\n",
    "\n",
    "ax.set_title(\"Comparação da predição da MLP com o valor real do mapa logístico\\n utilizando a rede neural ótima no conjunto de teste\")\n",
    "ax.set_ylabel('$x[n]$')\n",
    "ax.set_xlabel('$n$')\n",
    "ax.set_xlim(4900, 5000)\n",
    "    \n",
    "ax.grid(True)\n",
    "sns.despine()\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"../../../../images/mlp-basica/performance/mlp-basica-vs-logistic.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erro Quadrático Médio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_teste, y_pred)\n",
    "print(\"MSE = \" + str(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../../../../models/mlp-basica/mlp-basica-logistic.h5\", include_optimizer=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
