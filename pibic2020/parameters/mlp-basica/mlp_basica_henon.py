name='MLP-basica-henon'
batch_normalization='OFF'
batch_size=8
learning_rate=0.003
activation='sigmoid'
init_mode='glorot_normal'
n_neurons=50
n_hidden_layers=1